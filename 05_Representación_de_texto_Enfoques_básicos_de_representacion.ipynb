{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AgustinCocciardi/IA-Aplicada/blob/main/05_Representaci%C3%B3n_de_texto_Enfoques_b%C3%A1sicos_de_representacion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Representación de texto: Enfoques básicos de representacion\n"
      ],
      "metadata": {
        "id": "VRtT6UAwS3dO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## One Hot encoding"
      ],
      "metadata": {
        "id": "W7X8vORMWInA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Implementación Manual One Hot Encoding"
      ],
      "metadata": {
        "id": "9LxZ2LbnWf7-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tomemos los documentos que vimos en la ppt sin stopwords y hagamos un preprocesamiento básico. </br>\n",
        "1 - Pasemos todo a lowercase. </br>\n",
        "2 - Quitemos los puntos. </br>"
      ],
      "metadata": {
        "id": "N8Hdl8krS_f5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WpTEqCvnR3Ch",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0d4a1c3-e43b-4e28-a6fe-1b90bea63fd9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['estudiante cursa nlp', 'estudiante rinde examen']"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "documents = [\"estudiante cursa NLP.\", \"estudiante rinde examen.\"]\n",
        "processed_docs = [doc.lower().replace(\".\",\"\") for doc in documents]\n",
        "processed_docs"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Asignemosle un índice a cada una de las palabras de nuestro vocabulario"
      ],
      "metadata": {
        "id": "buJmzHpYTWgm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = {}\n",
        "count = 0\n",
        "for doc in processed_docs:\n",
        "    for word in doc.split():\n",
        "        if word not in vocab:\n",
        "            count = count +1\n",
        "            vocab[word] = count\n",
        "print(vocab)"
      ],
      "metadata": {
        "id": "Y9Lp6Lg0SkVt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e6c4d36-9e89-43fc-833a-323d1ba32c82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'estudiante': 1, 'cursa': 2, 'nlp': 3, 'rinde': 4, 'examen': 5}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Representamos cualquier string como one hot encoding Basado en las palabras de nuestro vocabulario.\n",
        "#Si la palabra existe en nuestro vocabulario, se devuelve su representación.\n",
        "#Si no esta en la lista se devuelve un vector con ceros.\n",
        "def get_onehot_vector(somestring):\n",
        "    onehot_encoded = []\n",
        "    for word in somestring.split():\n",
        "        temp = [0]*len(vocab)\n",
        "        if word in vocab:\n",
        "            temp[vocab[word]-1] = 1 # -1 es porque en python los arrays comienzan en 0\n",
        "        onehot_encoded.append(temp)\n",
        "    return onehot_encoded"
      ],
      "metadata": {
        "id": "TdGiEBr3SwY4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(processed_docs[1])\n",
        "get_onehot_vector(processed_docs[1]) #one hot representation para un texto de nuestro corpus."
      ],
      "metadata": {
        "id": "ew_uuyqiSz_d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53c997d1-7073-476b-e98a-48c43844491c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "estudiante rinde examen\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 0, 0, 0, 0], [0, 0, 0, 1, 0], [0, 0, 0, 0, 1]]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### One-hot encoding utilizando scikit-learn"
      ],
      "metadata": {
        "id": "iTIS0VirUmIk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "S1 = 'estudiante cursa nlp'\n",
        "S2 = 'estudiante rinde examen'"
      ],
      "metadata": {
        "id": "IFCN6owxU0KI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "\n",
        "data = [S1.split(), S2.split()]\n",
        "values = data[0] + data[1]\n",
        "print(\"The data: \",values)\n",
        "\n",
        "#Label Encoding\n",
        "label_encoder = LabelEncoder()\n",
        "integer_encoded = label_encoder.fit_transform(values)\n",
        "print(\"Label Encoded:\",integer_encoded)\n",
        "\n",
        "#One-Hot Encoding\n",
        "onehot_encoder = OneHotEncoder()\n",
        "onehot_encoded = onehot_encoder.fit_transform(data).toarray()\n",
        "print(\"Onehot Encoded Matrix:\\n\",onehot_encoded)"
      ],
      "metadata": {
        "id": "8yv7K6oaUzEy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5688cf5-a659-45c1-8d33-b705f3349dd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The data:  ['estudiante', 'cursa', 'nlp', 'estudiante', 'rinde', 'examen']\n",
            "Label Encoded: [1 0 3 1 4 2]\n",
            "Onehot Encoded Matrix:\n",
            " [[1. 1. 0. 0. 1.]\n",
            " [1. 0. 1. 1. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bag of Words"
      ],
      "metadata": {
        "id": "COPwh6wHWCGm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "documents = [\"estudiante cursa NLP.\", \"estudiante rinde examen.\"]\n",
        "processed_docs = [doc.lower().replace(\".\",\"\") for doc in documents]\n",
        "processed_docs"
      ],
      "metadata": {
        "id": "M3Xrvxd8W2oH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8401a52a-02e6-4b21-ae49-42a9a7bb1cb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['estudiante cursa nlp', 'estudiante rinde examen']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "#Revisemos la lista de los documentos\n",
        "print(\"Nuestro corpus: \", processed_docs)\n",
        "\n",
        "count_vect = CountVectorizer()\n",
        "#Creamos una representacion BOW para el corpus\n",
        "bow_rep = count_vect.fit_transform(processed_docs)\n",
        "\n",
        "#Miramos el vocabulary mapping del vectorizer\n",
        "print(\"Nuestro vocabulario: \", count_vect.vocabulary_)\n",
        "\n",
        "#Miremos la representación BOW para los primeros 2 documentos\n",
        "print(\"Representacion BoW para 'estudiante cursa nlp': \", bow_rep[0].toarray())\n",
        "print(\"Representacion BoW para 'estudiante rinde examen': \",bow_rep[1].toarray())\n",
        "\n",
        "#Obtengamos una nueva representación usando este vocabulario, para un nuevo texto\n",
        "temp = count_vect.transform([\"estudiante rinde nlp\"])\n",
        "print(\"Representacion BoW para 'estudiante rinde nlp':\", temp.toarray())\n",
        "\n",
        "#Veamos si hay palabras duplicadas:\n",
        "temp = count_vect.transform([\"estudiante rinde nlp nlp\"])\n",
        "print(\"Representacion BoW para 'estudiante rinde nlp nlp':\", temp.toarray())"
      ],
      "metadata": {
        "id": "yQZVYXrvW9IU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5dbf6ef0-5f06-4725-9a8b-639119cff8a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nuestro corpus:  ['estudiante cursa nlp', 'estudiante rinde examen']\n",
            "Nuestro vocabulario:  {'estudiante': 1, 'cursa': 0, 'nlp': 3, 'rinde': 4, 'examen': 2}\n",
            "Representacion BoW para 'estudiante cursa nlp':  [[1 1 0 1 0]]\n",
            "Representacion BoW para 'estudiante rinde examen':  [[0 1 1 0 1]]\n",
            "Representacion BoW para 'estudiante rinde nlp': [[0 1 0 1 1]]\n",
            "Representacion BoW para 'estudiante rinde nlp nlp': [[0 1 0 2 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#BoW con vectores binarios. Estos se usaban en tareas de analisis de sentimientos que no necesita saber la cantidad de veces que se repite una palabra sino su mera presencia.\n",
        "count_vect_bin = CountVectorizer(binary=True)\n",
        "count_vect_bin.fit(processed_docs)\n",
        "temp = count_vect_bin.transform([\"estudiante rinde nlp\"])\n",
        "print(\"Representacion BoW binario para 'estudiante rinde nlp':\", temp.toarray())"
      ],
      "metadata": {
        "id": "WF0QrY8MYXLJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de69b13d-af78-4394-f6bd-3517f151f4ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Representacion BoW binario para 'estudiante rinde nlp': [[0 1 0 1 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Comparamos resultados entre representaciones binarias y normales(Frecuencias)\n",
        "temp = count_vect.transform([\"estudiante rinde nlp nlp\"])\n",
        "print(\"Representacion BoW para 'estudiante rinde nlp nlp':\", temp.toarray())\n",
        "temp = count_vect_bin.transform([\"estudiante rinde nlp nlp\"])\n",
        "print(\"Representacion BoW binario para 'estudiante rinde nlp':\", temp.toarray())"
      ],
      "metadata": {
        "id": "reInmvYbY_XN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c63a389-7a9c-4e4b-a9e0-c4aab4bda9bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Representacion BoW para 'estudiante rinde nlp nlp': [[0 1 0 2 1]]\n",
            "Representacion BoW binario para 'estudiante rinde nlp': [[0 1 0 1 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bag of N-grams"
      ],
      "metadata": {
        "id": "ad8Vv3qkllEM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos a capturar un poco de contexto usando N-grams. Esto nos permite capturar algunas relaciones entre palabras."
      ],
      "metadata": {
        "id": "1O9SWv3XltG6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "documents = [\"estudiante cursa NLP.\", \"estudiante rinde examen.\"]\n",
        "processed_docs = [doc.lower().replace(\".\",\"\") for doc in documents]\n",
        "processed_docs"
      ],
      "metadata": {
        "id": "7RSVKnDXlkj1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c7a8eb8-7e5e-434d-c4df-be3c4f9e3fa1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['estudiante cursa nlp', 'estudiante rinde examen']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "#Vectorización Ngram con count vectorizer desde uni, bi hasta trigrams\n",
        "count_vect = CountVectorizer(ngram_range=(1,3))\n",
        "\n",
        "#Contruimos una representación BOW para el corpus\n",
        "bow_rep = count_vect.fit_transform(processed_docs)\n",
        "\n",
        "#Miremos como queda el vocabulary mapping\n",
        "print(\"Nuestro vocabulario: \", count_vect.vocabulary_)\n",
        "\n",
        "#Miremos la representación BOW de los primeros 2 documents\n",
        "print(\"Representacion BoW  para 'estudiante cursa nlp': \", bow_rep[0].toarray())\n",
        "print(\"Representacion BoW  para 'estudiante rinde examen': \",bow_rep[1].toarray())\n",
        "\n",
        "#Armemos la representación de un nuevo texto usando este vocabulario\n",
        "temp = count_vect.transform([\"estudiante rinde nlp\"])\n",
        "print(\"Representación BoN  para  'estudiante rinde nlp':\", temp.toarray())"
      ],
      "metadata": {
        "id": "Qh_s9uVTmHzq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bc0f5c4-32b2-4d53-e952-66059c1a1726"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nuestro vocabulario:  {'estudiante': 2, 'cursa': 0, 'nlp': 8, 'estudiante cursa': 3, 'cursa nlp': 1, 'estudiante cursa nlp': 4, 'rinde': 9, 'examen': 7, 'estudiante rinde': 5, 'rinde examen': 10, 'estudiante rinde examen': 6}\n",
            "Representacion BoW  para 'estudiante cursa nlp':  [[1 1 1 1 1 0 0 0 1 0 0]]\n",
            "Representacion BoW  para 'estudiante rinde examen':  [[0 0 1 0 0 1 1 1 0 1 1]]\n",
            "Representación BoN  para  'estudiante rinde nlp': [[0 0 1 0 0 1 0 0 1 1 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## TF-IDF"
      ],
      "metadata": {
        "id": "zOJiFrKkooNi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En todos los demás enfoques que hemos visto hasta ahora, todas las palabras del texto se tratan con la misma importancia. No existe la noción de que algunas palabras del documento sean más importantes que otras. TF-IDF se aborda esta problemática. Su objetivo es cuantificar la importancia de una palabra determinada en relación con otras palabras en el documento y en el corpus. Era un esquema de representación comúnmente utilizado para sistemas de recuperación de información, para extraer documentos relevantes de un corpus para una consulta de texto determinada."
      ],
      "metadata": {
        "id": "cEa_JZnro78-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "documents = [\"estudiante cursa NLP.\", \"estudiante rinde examen.\", \"profesor viaja universidad\", \"estudiante cursa virtual\"]\n",
        "processed_docs = [doc.lower().replace(\".\",\"\") for doc in documents]\n",
        "processed_docs"
      ],
      "metadata": {
        "id": "6rMxDlEao8uU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88d06958-124f-4199-f9bd-58a16df5d1a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['estudiante cursa nlp',\n",
              " 'estudiante rinde examen',\n",
              " 'profesor viaja universidad',\n",
              " 'estudiante cursa virtual']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf = TfidfVectorizer()\n",
        "bow_rep_tfidf = tfidf.fit_transform(processed_docs)\n",
        "\n",
        "print(\"IDF de todas las palabras en el vocabulario\",tfidf.idf_)\n",
        "print(\"-\"*10)\n",
        "\n",
        "print(\"Todas las palabras en el vocabulario\",tfidf.get_feature_names_out())\n",
        "print(\"-\"*10)\n",
        "\n",
        "print(\"Representacion TFIDF para todos documentos en nuestro corpus\\n\",bow_rep_tfidf.toarray())\n",
        "print(\"-\"*10)\n",
        "\n",
        "# Representación TFIDF para un texto nuevo que usa nuestro vocabulario.\n",
        "\n",
        "temp = tfidf.transform([\"estudiante rinde nlp\"])\n",
        "print(\"Representacion TFIDF para 'estudiante rinde nlp':\\n\", temp.toarray())"
      ],
      "metadata": {
        "id": "_Mbavu6GpZ75",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cc9af60-e264-4c3d-a374-86812346d2d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IDF de todas las palabras en el vocabulario [1.51082562 1.22314355 1.91629073 1.91629073 1.91629073 1.91629073\n",
            " 1.91629073 1.91629073 1.91629073]\n",
            "----------\n",
            "Todas las palabras en el vocabulario ['cursa' 'estudiante' 'examen' 'nlp' 'profesor' 'rinde' 'universidad'\n",
            " 'viaja' 'virtual']\n",
            "----------\n",
            "Representacion TFIDF para todos documentos en nuestro corpus\n",
            " [[0.55349232 0.44809973 0.         0.70203482 0.         0.\n",
            "  0.         0.         0.        ]\n",
            " [0.         0.41137791 0.64450299 0.         0.         0.64450299\n",
            "  0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.57735027 0.\n",
            "  0.57735027 0.57735027 0.        ]\n",
            " [0.55349232 0.44809973 0.         0.         0.         0.\n",
            "  0.         0.         0.70203482]]\n",
            "----------\n",
            "Representacion TFIDF para 'estudiante rinde nlp':\n",
            " [[0.         0.41137791 0.         0.64450299 0.         0.64450299\n",
            "  0.         0.         0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aplicar una técnica a un texto pequeño y uno grande."
      ],
      "metadata": {
        "id": "JcBNIEyH-Hzg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Textos a representar\n",
        "small_text = 'ayer fue viernes'\n",
        "large_text = 'el jueves pasado se ha disputado un partido de futbol entre el club atletico boca juniors y el cruzeiro esporte clube resultando en victoria por un solo gol para el equipo local cuyo tanto fue anotado por el delantero edinson cavani'\n",
        "\n",
        "# Crear un vectorizador BoW\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "# Ajustar el vectorizador a los textos\n",
        "vectorizer.fit([small_text, large_text])\n",
        "\n",
        "# Transformar los textos en vectores separados\n",
        "small_text_vector = vectorizer.transform([small_text]).toarray()\n",
        "large_text_vector = vectorizer.transform([large_text]).toarray()\n",
        "\n",
        "# Mostrar el vocabulario\n",
        "print(\"Vocabulario:\", vectorizer.get_feature_names_out())\n",
        "\n",
        "# Mostrar la representación BoW de small_text\n",
        "print(\"Vector BoW para small_text: \", small_text)\n",
        "print(small_text_vector)\n",
        "\n",
        "# Mostrar la representación BoW de large_text\n",
        "print(\"Vector BoW para large_text:\", large_text)\n",
        "print(large_text_vector)"
      ],
      "metadata": {
        "id": "PZC8uOkW-qv2",
        "outputId": "2008b81e-c36d-4450-8b6a-befb342cb711",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulario: ['anotado' 'atletico' 'ayer' 'boca' 'cavani' 'club' 'clube' 'cruzeiro'\n",
            " 'cuyo' 'de' 'delantero' 'disputado' 'edinson' 'el' 'en' 'entre' 'equipo'\n",
            " 'esporte' 'fue' 'futbol' 'gol' 'ha' 'jueves' 'juniors' 'local' 'para'\n",
            " 'partido' 'pasado' 'por' 'resultando' 'se' 'solo' 'tanto' 'un' 'victoria'\n",
            " 'viernes']\n",
            "Vector BoW para small_text:  ayer fue viernes\n",
            "[[0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]]\n",
            "Vector BoW para large_text: el jueves pasado se ha disputado un partido de futbol entre el club atletico boca juniors y el cruzeiro esporte clube resultando en victoria por un solo gol para el equipo local cuyo tanto fue anotado por el delantero edinson cavani\n",
            "[[1 1 0 1 1 1 1 1 1 1 1 1 1 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 1 0]]\n"
          ]
        }
      ]
    }
  ]
}